{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uy3a5XghZLL7",
        "outputId": "c0c7439b-0dcf-4cb4-e09f-02eb93e34f12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Describe the type of movies you like: french comedies\n",
            "\n",
            "Top Movie Recommendations:\n",
            "                  title genres overview original_language  similarity_score\n",
            "          Summer Nights comedy                         fr               1.0\n",
            "              Le Cactus comedy                         fr               1.0\n",
            " Le Nouveau Jean-Claude comedy                         fr               1.0\n",
            "La stratégie de l'échec comedy                         fr               1.0\n",
            "      Le maître d'école comedy                         fr               1.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "#I used KNN and\n",
        "def clean_text(text):\n",
        "    \"\"\"Remove special characters, convert to lowercase, remove stopwords, and lemmatize the text.\"\"\"\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", text.lower())\n",
        "    words = text.split()\n",
        "    cleaned_text = \" \".join(lemmatizer.lemmatize(word) for word in words if word not in stop_words)\n",
        "    return cleaned_text\n",
        "\n",
        "def load_data(file_path):\n",
        "    \"\"\"Load the movie dataset from a CSV file.\"\"\"\n",
        "    df = pd.read_csv(file_path, low_memory=False)\n",
        "    return df\n",
        "\n",
        "def check_columns(df):\n",
        "    \"\"\"Check if the necessary columns are present in the dataset.\"\"\"\n",
        "    required_columns = [\"title\", \"overview\", \"genres\", \"original_language\"]\n",
        "    for col in required_columns:\n",
        "        if col not in df.columns:\n",
        "            raise ValueError(f\"Dataset must contain '{col}' column.\")\n",
        "    return True\n",
        "\n",
        "def preprocess_data(df):\n",
        "    \"\"\"Fill missing overviews with empty strings and extract genres.\"\"\"\n",
        "    df[\"overview\"] = df[\"overview\"].fillna(\"\")\n",
        "    def extract_genres(genre_str):\n",
        "        try:\n",
        "            genres_list = ast.literal_eval(genre_str)\n",
        "            return \" \".join([genre[\"name\"] for genre in genres_list])\n",
        "        except (ValueError, SyntaxError):\n",
        "            return \"\"\n",
        "    df[\"genres\"] = df[\"genres\"].apply(extract_genres)\n",
        "    df[\"overview\"] = df[\"overview\"].apply(clean_text)\n",
        "    df[\"genres\"] = df[\"genres\"].apply(clean_text)\n",
        "    return df\n",
        "\n",
        "def filter_by_genre(df, user_input):\n",
        "    \"\"\"Filter movies based on user-specified genre keywords.\"\"\"\n",
        "    keywords = clean_text(user_input).split()\n",
        "    if not keywords:\n",
        "        return df\n",
        "    pattern = '|'.join(keywords)\n",
        "    filtered_df = df[df['genres'].str.contains(pattern, case=False)]\n",
        "    return filtered_df if not filtered_df.empty else df\n",
        "\n",
        "def create_content(df):\n",
        "    \"\"\"Combine genres and overview into a single content string.\"\"\"\n",
        "    df[\"content\"] = df[\"genres\"] + \" \" + df[\"overview\"]\n",
        "    return df\n",
        "\n",
        "def compute_tfidf(df):\n",
        "    \"\"\"Transform text data into TF-IDF vectors.\"\"\"\n",
        "    vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_df=0.85, min_df=0.01)\n",
        "    tfidf_matrix = vectorizer.fit_transform(df[\"content\"])\n",
        "    return tfidf_matrix, vectorizer\n",
        "\n",
        "def extract_language(user_input, language_mapping):\n",
        "    \"\"\"Extract language code from user input using a predefined mapping.\"\"\"\n",
        "    cleaned_input = clean_text(user_input)\n",
        "    for word in cleaned_input.split():\n",
        "        if word in language_mapping:\n",
        "            return language_mapping[word], word\n",
        "    return None, ''\n",
        "\n",
        "def recommend_movies(user_input, df, tfidf_matrix, vectorizer, top_n=5):\n",
        "    \"\"\"Find the most similar movies based on user input description using KNN.\"\"\"\n",
        "    language_mapping = {\n",
        "        'english': 'en',\n",
        "        'french': 'fr',\n",
        "        'spanish': 'es',\n",
        "        'german': 'de',\n",
        "        'italian': 'it',\n",
        "        'japanese': 'ja',\n",
        "        'chinese': 'zh',\n",
        "        'korean': 'ko',\n",
        "        'hindi': 'hi',\n",
        "        'russian': 'ru',\n",
        "        'dutch': 'nl',\n",
        "        'portuguese': 'pt',\n",
        "        'swedish': 'sv',\n",
        "        'turkish': 'tr',\n",
        "        'arabic': 'ar',\n",
        "    }\n",
        "    language_code, lang_keyword = extract_language(user_input, language_mapping)\n",
        "    # Remove the language keyword from the user input for genre/keyword processing\n",
        "    user_input_modified = clean_text(user_input)\n",
        "    if lang_keyword:\n",
        "        user_input_modified = user_input_modified.replace(lang_keyword, '').strip()\n",
        "    # Filter by genre using the modified user input\n",
        "    filtered_df = filter_by_genre(df, user_input_modified)\n",
        "    # Further filter by language if detected\n",
        "    if language_code:\n",
        "        filtered_df = filtered_df[filtered_df['original_language'] == language_code]\n",
        "\n",
        "    if filtered_df.empty:\n",
        "        return pd.DataFrame()\n",
        "    # Transform the modified user input for similarity comparison\n",
        "    user_vector = vectorizer.transform([user_input_modified])\n",
        "    # Fit KNN on the filtered data\n",
        "    knn = NearestNeighbors(n_neighbors=top_n, metric='cosine')\n",
        "    knn.fit(tfidf_matrix[filtered_df.index])\n",
        "    distances, indices = knn.kneighbors(user_vector)\n",
        "    # Prepare recommendations\n",
        "    recommendations = filtered_df.iloc[indices.flatten()][[\"title\", \"genres\", \"overview\", \"original_language\"]].copy()\n",
        "    recommendations['similarity_score'] = 1 - distances.flatten()\n",
        "    return recommendations.head(top_n)\n",
        "\n",
        "def main(file_path, user_input):\n",
        "    \"\"\"Run the movie recommendation system.\"\"\"\n",
        "    df = load_data(file_path)\n",
        "    check_columns(df)\n",
        "    df = preprocess_data(df)\n",
        "    df = create_content(df)\n",
        "    tfidf_matrix, vectorizer = compute_tfidf(df)\n",
        "    recommendations = recommend_movies(user_input, df, tfidf_matrix, vectorizer)\n",
        "    print(\"\\nTop Movie Recommendations:\")\n",
        "    if recommendations.empty:\n",
        "        print(\"No recommendations found.\")\n",
        "    else:\n",
        "        print(recommendations.to_string(index=False))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    file_path = \"/content/movies_metadata.csv\"\n",
        "    user_input = input(\"Describe the type of movies you like: \")\n",
        "    main(file_path, user_input)\n",
        "\n",
        "# My code uses Natural Language Processing (NLP) techniques to clean and preprocess text data before\n",
        "# applying a K-Nearest Neighbors (KNN) model for movie recommendations. I used these 2 in combination because\n",
        "# using onlt TF-IDF was not giving me very accurate results. The code begins by loading the dataset and\n",
        "# verifying essential columns like title, overview, genres, and original language. The text preprocessing\n",
        "# involves removing special characters, converting text to lowercase, and eliminating stopwords using the NLTK\n",
        "# stopwords list. It also applies lemmatization through the WordNet Lemmatizer to reduce words to their base\n",
        "# forms, ensuring better text consistency. Missing overviews are filled with empty strings, and genres are\n",
        "# extracted using ast.literal_eval to convert string representations of lists into actual lists. The cleaned\n",
        "# text data is combined into a single content feature, which is then transformed into a TF-IDF matrix to\n",
        "# represent text numerically. The user input undergoes similar text cleaning and is checked for language\n",
        "# keywords using a predefined mapping. The dataset is filtered based on the detected language and relevant\n",
        "# genres before applying a KNN model trained on the TF-IDF matrix to find the most similar movies based on\n",
        "# cosine similarity. The system then returns the top recommendations, including movie titles, genres,\n",
        "# overviews, and similarity scores."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}